{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/GD-NLP/blob/main/%5BGD_16%5D_Hugging_Face_Custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1aece43",
      "metadata": {
        "id": "b1aece43"
      },
      "source": [
        "# 16-6. ÌîÑÎ°úÏ†ùÌä∏ : Ïª§Ïä§ÌÖÄ ÌîÑÎ°úÏ†ùÌä∏ ÏßÅÏ†ë ÎßåÎì§Í∏∞\n",
        "\n",
        "- Ïã§Ïäµ ÏΩîÎìúÏóêÏÑú ÏàòÌñâÌï¥ Î≥∏ ÎÇ¥Ïö©ÏùÑ ÌÜ†ÎåÄÎ°ú, Ïù¥Î≤àÏóêÎäî GLUE datasetÏùò mnli taskÎ•º ÏàòÌñâÌïòÎäî ÌîÑÎ°úÏ†ùÌä∏Î•º Ïª§Ïä§ÌÖÄ ÌîÑÎ°úÏ†ùÌä∏ ÌòïÌÉúÎ°ú ÏßÑÌñâÌï¥ Î¥ÖÏãúÎã§.\n",
        "\n",
        "- mnli taskÎäî Ïù¥Ï†Ñ Ïä§ÌÖùÏóêÏÑú ÏÇ¨Ïö©Ìïú BERTÎ•º ÏÇ¨Ïö©ÌïòÎ©¥ ÌïôÏäµÏù¥ Ï†úÎåÄÎ°ú ÎêòÏßÄ ÏïäÏäµÎãàÎã§. [Ïó¨Í∏∞](https://huggingface.co/models)Î•º Ï∞∏Ï°∞ÌïòÏó¨ BERTÍ∞Ä ÏïÑÎãå Îã§Î•∏ Î™®Îç∏ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî. tensorflowÏôÄ Ìï¥Îãπ Î™®Îç∏Ïóê ÎåÄÌïú taskÎ°ú Í≤ÄÏÉâÌïòÎ©¥ ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎäî Î™®Îç∏Ïù¥ ÎÇòÏòµÎãàÎã§. Í∑∏ ÌõÑ ÏÑ†ÌÉùÌïú Î™®Îç∏Ïùò _tokenizer_ÏôÄ Ìï¥Îãπ Î™®Îç∏Ïóê ÎåÄÌïú task ÏôÄ Î™®Îç∏ Ïùò Ï†ïÎ≥¥Î•º [Ïó¨Í∏∞](https://huggingface.co/docs/transformers/index)ÏóêÏÑú Ï∞æÏïÑ Ïó¨Îü¨Î∂ÑÏùò ÌîÑÎ°úÏ†ùÌä∏Î•º ÏôÑÏÑ±Ìï¥ Î≥¥ÏÑ∏Ïöî.\n",
        "\n",
        "- Í∑∏ÎÉ• run_glue.pyÎ•º ÎèåÎ†§Î≥¥Îäî Î∞©ÏãùÏúºÎ°ú ÏßÑÌñâÌïòÎäî Í≤ÉÏùÑ ÏõêÌïòÎäî Í≤ÉÏùÄ ÏïÑÎãôÎãàÎã§. ÏïÑÎûòÏôÄ Í∞ôÏùÄ ÏàúÏÑúÎ•º ÏßÄÏºúÏÑú ÏßÑÌñâÌï¥ Ï£ºÏÑ∏Ïöî"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460f3c12",
      "metadata": {
        "id": "460f3c12"
      },
      "source": [
        "1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Î≤ÑÏ†ÑÏùÑ ÌôïÏù∏Ìï¥ Î¥ÖÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56067a96",
      "metadata": {
        "id": "56067a96",
        "outputId": "fa4846c9-31a9-4f5b-a8a7-4f19cba162b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n",
            "1.21.4\n",
            "4.11.3\n",
            "1.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification, AutoConfig\n",
        "from dataclasses import asdict\n",
        "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(transformers.__version__)\n",
        "print(argparse.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343e5573",
      "metadata": {
        "id": "343e5573"
      },
      "outputs": [],
      "source": [
        "DEPRECATION_WARNING = (\n",
        "    \"This {0} will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets \"\n",
        "    \"library. You can have a look at this example script for pointers: \"\n",
        "    \"https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b2f6fd",
      "metadata": {
        "id": "20b2f6fd"
      },
      "source": [
        "# STEP 1. mnli Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Î∂ÑÏÑùÌï¥ Î≥¥Í∏∞\n",
        "\n",
        "- tensorflow-datasetsÎ•º Ïù¥Ïö©ÌïòÏó¨ glue/mnliÎ•º Îã§Ïö¥Î°úÎìúÌïòÎ†§Î©¥ tensorflow-datasets ÎùºÏù¥Î∏åÎü¨Î¶¨ Î≤ÑÏ†ÑÏùÑ Ïò¨Î†§Ïïº Ìï©ÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1050c7",
      "metadata": {
        "collapsed": true,
        "id": "bf1050c7",
        "outputId": "ffb721a8-ff7f-47f6-cd3a-22de5365a298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.9/site-packages (4.4.0)\n",
            "Collecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.7.0-py3-none-any.whl (4.7 MB)\n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.7 MB 7.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (0.12.0)\n",
            "Collecting etils[epath]\n",
            "  Downloading etils-0.8.0-py3-none-any.whl (127 kB)\n",
            "     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 127 kB 83.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (2.26.0)\n",
            "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (0.3.4)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.16.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: promise in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (3.19.1)\n",
            "Requirement already satisfied: termcolor in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.1.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.21.4)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (4.62.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: zipp in /opt/conda/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets) (3.6.0)\n",
            "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets) (4.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
            "Installing collected packages: etils, toml, tensorflow-datasets\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.4.0\n",
            "    Uninstalling tensorflow-datasets-4.4.0:\n",
            "      Successfully uninstalled tensorflow-datasets-4.4.0\n",
            "Successfully installed etils-0.8.0 tensorflow-datasets-4.7.0 toml-0.10.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-datasets -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da6f31f9",
      "metadata": {
        "collapsed": true,
        "colab": {
          "referenced_widgets": [
            "b4411f1927b943fcadbec1657765439e",
            "796d3a8c10c34b81a1aeb7e4ca1d56db",
            "b57f564604e5475b81f2e8dca8cc7841",
            ""
          ]
        },
        "id": "da6f31f9",
        "outputId": "16606f58-4c10-4002-d5cd-5f4a03c34ec3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: glue/mnli/2.0.0\n",
            "INFO:absl:Load dataset info from /tmp/tmp4thpf0xxtfds\n",
            "INFO:absl:Generating dataset glue (/aiffel/tensorflow_datasets/glue/mnli/2.0.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset 298.29 MiB (download: 298.29 MiB, generated: 100.56 MiB, total: 398.85 MiB) to /aiffel/tensorflow_datasets/glue/mnli/2.0.0...\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4411f1927b943fcadbec1657765439e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "796d3a8c10c34b81a1aeb7e4ca1d56db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b57f564604e5475b81f2e8dca8cc7841",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading https://dl.fbaipublicfiles.com/glue/data/MNLI.zip into /aiffel/tensorflow_datasets/downloads/dl.fbaipublicfiles.com_glue_MNLIdNe8cK2kTBCG0bqBz2JxwShRT2KfuO3NVIwROTnjtfI.zip.tmp.878a1dbca1584f0e8a6934cfc4813665...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/5 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-train.tfrecord...:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-train.tfrecord. Number of examples: 392702 (shards: [392702])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_matched examples...:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-validation_matched.tfrecord...:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-validation_matched.tfrecord. Number of examples: 9815 (shards: [9815])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_mismatched examples...:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-validation_mismatched.tfrecord...:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-validation_mismatched.tfrecord. Number of examples: 9832 (shards: [9832])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test_matched examples...:   0%|          | 0/9796 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-test_matched.tfrecord...:   0%|          | 0/9796 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-test_matched.tfrecord. Number of examples: 9796 (shards: [9796])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test_mismatched examples...:   0%|          | 0/9847 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-test_mismatched.tfrecord...:   0%|          | 0/9847 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-test_mismatched.tfrecord. Number of examples: 9847 (shards: [9847])\n",
            "INFO:absl:Constructing tf.data.Dataset glue for split None, from /aiffel/tensorflow_datasets/glue/mnli/2.0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset glue downloaded and prepared to /aiffel/tensorflow_datasets/glue/mnli/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "392702"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data, info = tfds.load('glue/mnli', with_info=True)\n",
        "info.splits['train'].num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27196c4",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3a2b0bfa9cb5438d941911b86b9acc4a",
            "c2f9d98b9e2d498fa3029f9f8bc33198",
            "1044257d27e64f1e9108483e587ce794",
            "",
            "3deb8da90dca457bb8591ebbf48a4e69"
          ]
        },
        "id": "c27196c4",
        "outputId": "333e8caa-66c3-4c5f-f9c4-01ca613bec41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a2b0bfa9cb5438d941911b86b9acc4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2f9d98b9e2d498fa3029f9f8bc33198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /aiffel/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1044257d27e64f1e9108483e587ce794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset glue downloaded and prepared to /aiffel/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3deb8da90dca457bb8591ebbf48a4e69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 392702\n",
            "    })\n",
            "    validation_matched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9815\n",
            "    })\n",
            "    validation_mismatched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9832\n",
            "    })\n",
            "    test_matched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9796\n",
            "    })\n",
            "    test_mismatched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9847\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "huggingface_mnli_dataset = load_dataset('glue', 'mnli')\n",
        "print(huggingface_mnli_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8dec28",
      "metadata": {
        "id": "ba8dec28",
        "outputId": "2ddc1d90-1167-4a49-eac5-621dd6ddc593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 392702\n",
              "    })\n",
              "    validation_matched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9815\n",
              "    })\n",
              "    validation_mismatched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9832\n",
              "    })\n",
              "    test_matched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9796\n",
              "    })\n",
              "    test_mismatched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9847\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "huggingface_mnli_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3843ca05",
      "metadata": {
        "id": "3843ca05"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30cfd156",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a8b58d40f361449e9f246d1db6cbb0f3",
            "e76b29daa77449e89eb60f84d358c608",
            "c21462c640564ffaaa72f3a0d8e65d12",
            "2d81899fb64941c9a8c74145e996184e",
            "d63c7e4936a8406387f87fb435e986d1",
            "346b71e07231445ebd23934c18665ae8"
          ]
        },
        "id": "30cfd156",
        "outputId": "6315373e-f9b2-4138-a682-5e85005f4f1b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8b58d40f361449e9f246d1db6cbb0f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e76b29daa77449e89eb60f84d358c608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c21462c640564ffaaa72f3a0d8e65d12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d81899fb64941c9a8c74145e996184e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d63c7e4936a8406387f87fb435e986d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "346b71e07231445ebd23934c18665ae8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "huggingface_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
        "\n",
        "huggingface_model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e42f90f",
      "metadata": {
        "id": "8e42f90f",
        "outputId": "11789851-f5d5-42e0-df7c-bec047cdd0f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TakeDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['train'].take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3ce509",
      "metadata": {
        "id": "ea3ce509",
        "outputId": "7c708d7f-19d8-48bb-aefb-01b1b9222ca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{Split('train'): <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'validation_matched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'validation_mismatched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'test_matched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'test_mismatched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141da9dc",
      "metadata": {
        "id": "141da9dc",
        "outputId": "232893fe-d48f-4234-df30-7a1c9fbdd6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', shape=(), dtype=string)\n",
            "tf.Tensor(b'Meaningful partnerships with stakeholders is crucial.', shape=(), dtype=string)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# Îç∞Ïù¥ÌÑ∞ÏÖã ÏïàÏóê Ïñ¥Îñ§ Ìï≠Î™©Ïù¥ Ï†ïÏùòÎêòÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏\n",
        "\n",
        "examples = data['train'].take(1)\n",
        "for example in examples:\n",
        "    premise = example['premise']\n",
        "    hypothesis = example['hypothesis']\n",
        "    label = example['label']\n",
        "    print(premise)\n",
        "    print(hypothesis)\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d48aa1",
      "metadata": {
        "id": "b3d48aa1"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"\n",
        "        Gets an example from a dict with tensorflow tensors.\n",
        "\n",
        "        Args:\n",
        "            tensor_dict: Keys and values should match the corresponding Glue\n",
        "                tensorflow_dataset examples.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of :class:`InputExample` for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of :class:`InputExample` for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of :class:`InputExample` for the test set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def tfds_map(self, example):\n",
        "        \"\"\"\n",
        "        Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
        "        examples to the correct format.\n",
        "        \"\"\"\n",
        "        if len(self.get_labels()) > 1:\n",
        "            example.label = self.get_labels()[int(example.label)]\n",
        "        return example\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f199e8",
      "metadata": {
        "id": "91f199e8"
      },
      "source": [
        "# STEP 2. MNLIProcessorÌÅ¥ÎûòÏä§ Íµ¨ÌòÑÌïòÍ∏∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740062d7",
      "metadata": {
        "id": "740062d7"
      },
      "outputs": [],
      "source": [
        "class MNLIProcessor(DataProcessor):\n",
        "    \"\"\"Processor for the MNLI data set (GLUE version).\"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return InputExample(\n",
        "            tensor_dict[\"idx\"].numpy(),\n",
        "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
        "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
        "            str(tensor_dict[\"label\"].numpy()),\n",
        "        )\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            text_a = line[8]\n",
        "            text_b = line[9]\n",
        "            label = None if set_type == \"test\" else line[-1]\n",
        "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "        return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6024e8",
      "metadata": {
        "id": "8e6024e8"
      },
      "outputs": [],
      "source": [
        "# ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ï≤òÎ¶¨ÌïòÏó¨ Î™®Îç∏Ïóê ÏûÖÎ†•Ìï† Ïàò ÏûàÎèÑÎ°ù Ï†ïÎ¶¨Ìï¥ Ï£ºÎäî ÌÅ¥ÎûòÏä§\n",
        "\n",
        "class MrpcProcessor(DataProcessor):\n",
        "    \"\"\"Processor for the MRPC data set (GLUE version).\"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return InputExample(\n",
        "            tensor_dict[\"idx\"].numpy(),\n",
        "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
        "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
        "            str(tensor_dict[\"label\"].numpy()),\n",
        "        )\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            text_a = line[8]\n",
        "            text_b = line[9]\n",
        "            label = None if set_type == \"test\" else line[-1]\n",
        "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "        return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d57021",
      "metadata": {
        "scrolled": true,
        "id": "28d57021",
        "outputId": "bdb0efdb-99f2-40bb-e191-1e085234164d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------ÏõêÎ≥∏Îç∞Ïù¥ÌÑ∞------\n",
            "{'hypothesis': <tf.Tensor: shape=(), dtype=string, numpy=b'Meaningful partnerships with stakeholders is crucial.'>, 'idx': <tf.Tensor: shape=(), dtype=int32, numpy=16399>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'premise': <tf.Tensor: shape=(), dtype=string, numpy=b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.'>}\n",
            "------processor Í∞ÄÍ≥µÎç∞Ïù¥ÌÑ∞------\n",
            "InputExample(guid=16399, text_a='In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', text_b='Meaningful partnerships with stakeholders is crucial.', label='1')\n"
          ]
        }
      ],
      "source": [
        "processor = MnliProcessor()\n",
        "examples = data['train'].take(1)\n",
        "\n",
        "for example in examples:\n",
        "    print('------ÏõêÎ≥∏Îç∞Ïù¥ÌÑ∞------')\n",
        "    print(example)  \n",
        "    example = processor.get_example_from_tensor_dict(example)\n",
        "    print('------processor Í∞ÄÍ≥µÎç∞Ïù¥ÌÑ∞------')\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa55b70",
      "metadata": {
        "id": "daa55b70",
        "outputId": "0a64b8e0-363b-4ecc-90e9-9beb9c43c771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InputExample(guid=16399, text_a='In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', text_b='Meaningful partnerships with stakeholders is crucial.', label='entailment')\n"
          ]
        }
      ],
      "source": [
        "examples = (data['train'].take(1))\n",
        "for example in examples:\n",
        "    example = processor.get_example_from_tensor_dict(example)\n",
        "    example = processor.tfds_map(example)\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740eddba",
      "metadata": {
        "id": "740eddba",
        "outputId": "ced68068-f886-4f1e-9606-13af7f3ae0a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['contradiction', 'entailment', 'neutral']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ïã§Ï†ú labelÏùÑ ÌôïÏù∏ÌïòÏó¨ Binary Classification Î¨∏Ï†úÎ°ú Ïûò Ï†ïÏùòÎêòÍ≥† ÏûàÎäîÏßÄ ÌôïÏù∏\n",
        "label_list = processor.get_labels()\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c98293",
      "metadata": {
        "id": "b4c98293",
        "outputId": "014fe71c-a09e-4f3d-b922-cf1cad2f6b18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'contradiction': 0, 'entailment': 1, 'neutral': 2}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "label_map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843dbd55",
      "metadata": {
        "id": "843dbd55"
      },
      "source": [
        "# STEP 3. ÏúÑÏóêÏÑú Íµ¨ÌòÑÌïú processor Î∞è HuggingfaceÏóêÏÑú Ï†úÍ≥µÌïòÎäî tokenizerÎ•º ÌôúÏö©ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨ÏÑ±ÌïòÍ∏∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a4d5dce",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ee5ac8c878214c8e9c53549e1008b46f",
            "3cb46157c78a4b2b93131ac93ed2e4d5",
            "76ba73f817044bf5943b52ccde4a6385",
            "9392b440e45448b5a455404e6f0c0bb8",
            "e855ab4512344b1b96f3c6f14dfec3db"
          ]
        },
        "id": "4a4d5dce",
        "outputId": "957933a4-2e5d-4507-8bde-f3704338e135"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee5ac8c878214c8e9c53549e1008b46f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/258 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cb46157c78a4b2b93131ac93ed2e4d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ba73f817044bf5943b52ccde4a6385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9392b440e45448b5a455404e6f0c0bb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e855ab4512344b1b96f3c6f14dfec3db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "huggingface_tokenizer = AutoTokenizer.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")\n",
        "\n",
        "huggingface_model = AutoModelForSequenceClassification.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c209be8",
      "metadata": {
        "collapsed": true,
        "id": "6c209be8",
        "outputId": "49a93e93-ed97-4784-dd22-267f7d974952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'premise': ['Conceptually cream skimming has two basic dimensions - product and geography.', 'you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him', 'One of our number will carry out your instructions minutely.', 'How do you know? All this is their information again.', \"yeah i tell you what though if you go price some of those tennis shoes i can see why now you know they're getting up in the hundred dollar range\"], 'hypothesis': ['Product and geography are what make cream skimming work. ', 'You lose the things to the following level if the people recall.', 'A member of my team will execute your orders with immense precision.', 'This information belongs to them.', 'The tennis shoes have a range of prices.'], 'label': [1, 0, 0, 0, 1], 'idx': [0, 1, 2, 3, 4]}\n",
            "{'input_ids': [[101, 17158, 2135, 6949, 8301, 25057, 2038, 2048, 3937, 9646, 1011, 4031, 1998, 10505, 1012, 102, 4031, 1998, 10505, 2024, 2054, 2191, 6949, 8301, 25057, 2147, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2017, 2113, 2076, 1996, 2161, 1998, 1045, 3984, 2012, 2012, 2115, 2504, 7910, 2017, 4558, 2068, 2000, 1996, 2279, 2504, 2065, 2065, 2027, 5630, 2000, 9131, 1996, 1996, 6687, 2136, 1996, 13980, 5630, 2000, 2655, 2000, 9131, 1037, 3124, 2013, 6420, 1037, 2059, 1037, 3313, 1037, 3124, 3632, 2039, 2000, 5672, 2032, 1998, 1037, 2309, 1037, 3124, 3632, 2039, 2000, 5672, 2032, 102, 2017, 4558, 1996, 2477, 2000, 1996, 2206, 2504, 2065, 1996, 2111, 9131, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2028, 1997, 2256, 2193, 2097, 4287, 2041, 2115, 8128, 3371, 2135, 1012, 102, 1037, 2266, 1997, 2026, 2136, 2097, 15389, 2115, 4449, 2007, 14269, 11718, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2129, 2079, 2017, 2113, 1029, 2035, 2023, 2003, 2037, 2592, 2153, 1012, 102, 2023, 2592, 7460, 2000, 2068, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3398, 1045, 2425, 2017, 2054, 2295, 2065, 2017, 2175, 3976, 2070, 1997, 2216, 5093, 6007, 1045, 2064, 2156, 2339, 2085, 2017, 2113, 2027, 1005, 2128, 2893, 2039, 1999, 1996, 3634, 7922, 2846, 102, 1996, 5093, 6007, 2031, 1037, 2846, 1997, 7597, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ],
      "source": [
        "def transform(data):\n",
        "  return huggingface_tokenizer(\n",
        "      data['premise'],\n",
        "      data['hypothesis'],\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_token_type_ids = False,\n",
        "      )\n",
        "  \n",
        "examples = huggingface_mnli_dataset['train'][:5]\n",
        "examples_transformed = transform(examples)\n",
        "\n",
        "print(examples)\n",
        "print(examples_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "543144f0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e5db5b3355a04619844c82d34728f0b6",
            "c6c611f302ab44bba1e9fe18722aaaa0",
            "f2fb61fbe6a14c848744c09bc169b6dc",
            "19ef566409774878b2c9b866b459fcd5",
            "49db9b578ca54e20b65c89791f81cf4e"
          ]
        },
        "id": "543144f0",
        "outputId": "ffe3f1c6-9825-46d5-d04b-e84ce29cbc34"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5db5b3355a04619844c82d34728f0b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/393 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c611f302ab44bba1e9fe18722aaaa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2fb61fbe6a14c848744c09bc169b6dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19ef566409774878b2c9b866b459fcd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49db9b578ca54e20b65c89791f81cf4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoded_dataset = huggingface_mnli_dataset.map(transform, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f148e0",
      "metadata": {
        "id": "39f148e0"
      },
      "outputs": [],
      "source": [
        "def _glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"claasification\") :\n",
        "    if max_length is None :\n",
        "        max_length = tokenizer.max_len\n",
        "    if label_list is None:\n",
        "        label_list = processor.get_labels()\n",
        "        print(\"Using label list %s\" % (label_list))\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "    labels = [label_map[example.label] for example in examples]\n",
        "\n",
        "    batch_encoding = tokenizer(\n",
        "        [(example.text_a, example.text_b) for example in examples],\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    for i in range(len(examples)):\n",
        "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "\n",
        "        feature = InputFeatures(**inputs, label=labels[i])\n",
        "        features.append(feature)\n",
        "\n",
        "    for i, example in enumerate(examples[:5]):\n",
        "        print(\"*** Example ***\")\n",
        "        print(\"guid: %s\" % (example.guid))\n",
        "        print(\"features: %s\" % features[i])\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d2c08b",
      "metadata": {
        "id": "08d2c08b"
      },
      "outputs": [],
      "source": [
        "def tf_glue_convert_examples_to_features(examples, \n",
        "                                         tokenizer, \n",
        "                                         max_length, \n",
        "                                         processor, \n",
        "                                         label_list=None, \n",
        "                                         output_mode=\"classification\") :\n",
        "    \"\"\"\n",
        "    :param examples: tf.data.Dataset\n",
        "    :param tokenizer: pretrained tokenizer\n",
        "    :param max_length: exampleÏùò ÏµúÎåÄ Í∏∏Ïù¥(Í∏∞Î≥∏Í∞í : tokenizerÏùò max_len)\n",
        "    :param task: GLUE task Ïù¥Î¶Ñ\n",
        "    :param label_list: ÎùºÎ≤® Î¶¨Ïä§Ìä∏\n",
        "    :param output_mode: \"regression\" or \"classification\"\n",
        "\n",
        "    :return: taskÏóê ÎßûÎèÑÎ°ù featureÍ∞Ä Íµ¨ÏÑ±Îêú tf.data.Dataset\n",
        "    \"\"\"\n",
        "    examples = [processor.tfds_map(processor.get_example_from_tensor_dict(example)) for example in examples]\n",
        "    features = _glue_convert_examples_to_features(examples, tokenizer, max_length, processor)\n",
        "    label_type = tf.int64\n",
        "\n",
        "    def gen():\n",
        "        for ex in features:\n",
        "            d = {k: v for k, v in asdict(ex).items() if v is not None}\n",
        "            label = d.pop(\"label\")\n",
        "            yield (d, label)\n",
        "\n",
        "    input_names = [\"input_ids\"] + tokenizer.model_input_names\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({k: tf.int32 for k in input_names}, label_type),\n",
        "        ({k: tf.TensorShape([None]) for k in input_names}, tf.TensorShape([])),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d3fddc",
      "metadata": {
        "id": "83d3fddc"
      },
      "outputs": [],
      "source": [
        "# ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú Î™®Îç∏Ïóê Ï†ÑÎã¨Îê† tf.data.Dataset Ïù∏Ïä§ÌÑ¥Ïä§Î•º ÏÉùÏÑ±\n",
        "train_dataset = tf_glue_convert_examples_to_features(data['train'], \n",
        "                                                     tokenizer, max_length=128, processor=processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b3964f",
      "metadata": {
        "id": "39b3964f",
        "outputId": "e8d933a4-06e7-42f7-ac13-68a3a434a2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
            "array([  101,  1999,  5038,  1997,  2122, 13136,  1010,  1048, 11020,\n",
            "        2038,  2499, 29454, 29206, 14626,  2144,  2786,  2000, 16636,\n",
            "        1996, 10908,  1997,  1996,  2110,  4041,  6349,  1998,  2000,\n",
            "        5323, 15902, 13797,  2007, 22859,  6461,  2012,  6469,  2075,\n",
            "        1037,  2047, 25353, 14905, 10735,  2483,  2090,  1996,  2976,\n",
            "       10802,  1998, 15991,  1997,  3423,  2578,  4804,  1012,   102,\n",
            "       15902, 13797,  2007, 22859,  2003, 10232,  1012,   102,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
            "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
          ]
        }
      ],
      "source": [
        "examples = train_dataset.take(1)\n",
        "for example in examples:\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441c6a20",
      "metadata": {
        "id": "441c6a20"
      },
      "outputs": [],
      "source": [
        "# train Îç∞Ïù¥ÌÑ∞ÏÖã\n",
        "train_dataset = tf_glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, processor=processor)\n",
        "train_dataset_batch = train_dataset.shuffle(100).batch(16).repeat(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbc9562",
      "metadata": {
        "id": "bdbc9562"
      },
      "outputs": [],
      "source": [
        "# validation Îç∞Ïù¥ÌÑ∞ÏÖã\n",
        "validation_dataset = tf_glue_convert_examples_to_features(data['validation_matched'], tokenizer, max_length=128, processor=processor)\n",
        "validation_dataset_batch = validation_dataset.shuffle(100).batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabbdeef",
      "metadata": {
        "id": "cabbdeef"
      },
      "outputs": [],
      "source": [
        "# test Îç∞Ïù¥ÌÑ∞ÏÖã\n",
        "test_dataset = tf_glue_convert_examples_to_features(data['test_matched'], tokenizer, max_length=128, processor=processor)\n",
        "test_dataset_batch = test_dataset.shuffle(100).batch(16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a58fa6d",
      "metadata": {
        "id": "3a58fa6d"
      },
      "source": [
        "# STEP 4. modelÏùÑ ÏÉùÏÑ±ÌïòÏó¨ ÌïôÏäµ Î∞è ÌÖåÏä§Ìä∏Î•º ÏßÑÌñâÌï¥ Î≥¥Í∏∞\n",
        "\n",
        "- ÌòπÏãú STEP 2Ïùò ÏßÑÌñâÏóê Ïñ¥Î†§ÏõÄÏùÑ Í≤™Í≥† Í≥ÑÏã†Îã§Î©¥ transformer ÌîÑÎ°úÏ†ùÌä∏ ÎÇ¥Î∂ÄÎ•º ÏÇ¥Ìé¥Î≥¥ÏãúÎ©¥ Ï∞∏Í≥†Ìï†ÎßåÌïú ÏòàÏãú ÏΩîÎìúÎ•º Ï∞æÏïÑÎ≥º Ïàò ÏûàÏùÑ Í≤ÉÏûÖÎãàÎã§. transformersÏùò Í≥µÏãù [github](https://github.com/huggingface/transformers)ÏùÑ Ï∞∏Í≥†ÌïòÎäî Í≤ÉÎèÑ Ï¢ãÏùÄ Î∞©Î≤ïÏù¥ÏóêÏöî!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7a7f3f",
      "metadata": {
        "id": "5a7a7f3f"
      },
      "outputs": [],
      "source": [
        "num_classes = len(processor.get_labels())\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3be0d7",
      "metadata": {
        "scrolled": true,
        "id": "2f3be0d7",
        "outputId": "21694dc5-1f8e-4550-a4e0-230e94ae106e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b1bf89",
      "metadata": {
        "collapsed": true,
        "id": "c0b1bf89",
        "outputId": "9f2ac483-fb63-45c9-f4ab-0cbe31c7d5c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:769 train_step\n        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:212 __call__\n        batch_dim = tf.shape(y_t)[0]\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1041 _slice_helper\n        return strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1214 strided_slice\n        op = gen_array_ops.strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10538 strided_slice\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_13/1303136026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Ïù¥Ï†Ñ Ïä§ÌÖùÏóêÏÑú Î∞∞ÏπòÏ≤òÎ¶¨Î•º ÏßÑÌñâÌïú Îç∞Ïù¥ÌÑ∞ÏÖã(xxxx_dataset_batch)ÏùÑ ÌôúÏö©\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(train_dataset, \n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m115\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:769 train_step\n        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:212 __call__\n        batch_dim = tf.shape(y_t)[0]\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1041 _slice_helper\n        return strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1214 strided_slice\n        op = gen_array_ops.strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10538 strided_slice\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n"
          ]
        }
      ],
      "source": [
        "# Ïù¥ÎØ∏ Ïûò ÌõàÎ†®Îêú BERT Î™®Îç∏ÏùÑ Í∞ÄÏ†∏Îã§Í∞Ä fine-tuningÌïòÎäî ÏûëÏóÖ\n",
        "\n",
        "# Ïù¥Ï†Ñ Ïä§ÌÖùÏóêÏÑú Î∞∞ÏπòÏ≤òÎ¶¨Î•º ÏßÑÌñâÌïú Îç∞Ïù¥ÌÑ∞ÏÖã(xxxx_dataset_batch)ÏùÑ ÌôúÏö©\n",
        "model.fit(train_dataset, \n",
        "          epochs=3, \n",
        "          steps_per_epoch=115, \n",
        "          validation_data=validation_dataset_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951845cd",
      "metadata": {
        "id": "951845cd"
      },
      "outputs": [],
      "source": [
        "# TrainerÏùÑ ÌôúÏö©ÌïòÎäî ÌòïÌÉúÎ°ú Î™®Îç∏ Ïû¨ÏÉùÏÑ±\n",
        "from transformers import Trainer, TrainingArguments\n",
        "output_dir = os.getenv('HOME')+'/aiffel/transformers'\n",
        "metric_name = 'accuracy'\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir, # outputÏù¥ Ï†ÄÏû•Îê† Í≤ΩÎ°ú\n",
        "    evaluation_strategy=\"epoch\", #evaluationÌïòÎäî ÎπàÎèÑ\n",
        "    learning_rate = 2e-5, #learning_rate\n",
        "    per_device_train_batch_size = 8, # Í∞Å device Îãπ batch size\n",
        "    per_device_eval_batch_size = 8, # evaluation ÏãúÏóê batch size\n",
        "    num_train_epochs = 1, # train ÏãúÌÇ¨ Ï¥ù epochs\n",
        "    weight_decay = 0.01, # weight decay\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bf190c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "43e0551949024f378e3b4492a5843291"
          ]
        },
        "id": "93bf190c",
        "outputId": "f92539ea-65ce-4a90-992a-3100e97816ea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43e0551949024f378e3b4492a5843291",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric('glue', 'mnli')\n",
        "\n",
        "def compute_metrics(eval_pred):    \n",
        "    predictions,labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references = labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a35ff76",
      "metadata": {
        "id": "0a35ff76",
        "outputId": "05f42a46-4ee2-487e-8a00-b6ef27707a21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\n",
            "***** Running training *****\n",
            "  Num examples = 392702\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 49088\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49088' max='49088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [49088/49088 5:55:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.292800</td>\n",
              "      <td>0.930875</td>\n",
              "      <td>0.813653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17500/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-21000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-21000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-21000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-21500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-21500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-21500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-24000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-24000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-24500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-24500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-33000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-33000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-33000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-33500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-33500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-33500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35000/config.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-38000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-38000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-38000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-38500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-38500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-38500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-39000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-39000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-39000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-39500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-39500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-39500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-40000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-40000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-40000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-40500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-40500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-40500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-41000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-41000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-41000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-41500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-41500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-41500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-42000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-42000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-42000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-42500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-42500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-42500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-43000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-43000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-43000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-43500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-43500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-43500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-44000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-44000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-44000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-44500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-44500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-44500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-45000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-45000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-45000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-45500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-45500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-45500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-46000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-46000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-46000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-46500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-46500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-46500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-47000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-47000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-47000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-47500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-47500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-47500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-48000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-48000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-48000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-48500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-48500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-48500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-49000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-49000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-49000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=49088, training_loss=0.29948605905922016, metrics={'train_runtime': 21341.9578, 'train_samples_per_second': 18.4, 'train_steps_per_second': 2.3, 'total_flos': 5.202114009364685e+16, 'train_loss': 0.29948605905922016, 'epoch': 1.0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=huggingface_model,                           # ÌïôÏäµÏãúÌÇ¨ model\n",
        "    args=training_arguments,                  # TrainingArgumentsÏùÑ ÌÜµÌï¥ ÏÑ§Ï†ïÌïú arguments\n",
        "    train_dataset=encoded_dataset['train'],    # training dataset\n",
        "    eval_dataset=encoded_dataset['validation_matched'],       # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03676efd",
      "metadata": {
        "id": "03676efd",
        "outputId": "28f2075a-2ab5-49fd-a04f-9b964642b01a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9796\n",
            "  Batch size = 8\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_534/2286787279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_matched'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2114\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m             \u001b[0;31m# Update containers on host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2487\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ],
      "source": [
        "trainer.evaluate(encoded_dataset['test_matched'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÌöåÍ≥†"
      ],
      "metadata": {
        "id": "lX7qGW4XKysW"
      },
      "id": "lX7qGW4XKysW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ïù¥Î≤à ÌîÑÎ°úÏ†ùÌä∏ÏóêÏÑú Ïñ¥Î†§Ïõ†Îçò Ï†ê\n",
        " \n",
        "(1) CUDA Î©îÎ™®Î¶¨ Ïò§Î•òÍ∞Ä Í≥ÑÏÜç Îñ† ÌïôÏäµ Í≥ºÏ†ïÏù¥ ÏâΩÏßÄÏïäÏïòÏäµÎãàÎã§."
      ],
      "metadata": {
        "id": "ojmxzLRyK1cS"
      },
      "id": "ojmxzLRyK1cS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. ÌîÑÎ°úÏ†ùÌä∏Î•º ÏßÑÌñâÌïòÎ©¥ÏÑú ÏïåÍ≤åÎêú Î∂ÄÎ∂Ñ ÎòêÎäî ÏïÑÏßÅ Ïù¥Ìï¥ÌïòÏßÄ Î™ªÌïú Î∂ÄÎ∂Ñ\n",
        "\n",
        "(1) CUDA Î©îÎ™®Î¶¨ Ïò§Î•òÎ•º Ìï¥Í≤∞ÌïòÍ∏∞ ÏúÑÌïú Î∞©Î≤ï\n",
        "- batch_size Ï°∞Ï†à\n",
        "- Îçî ÏûëÏùÄ Î™®Îç∏ Î∂àÎü¨Ïò§Í∏∞\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cMgNvnfQLhyy"
      },
      "id": "cMgNvnfQLhyy"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}