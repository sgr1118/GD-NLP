{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgr1118/GD-NLP/blob/main/%5BGD_16%5D_Hugging_Face_Custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1aece43",
      "metadata": {
        "id": "b1aece43"
      },
      "source": [
        "# 16-6. 프로젝트 : 커스텀 프로젝트 직접 만들기\n",
        "\n",
        "- 실습 코드에서 수행해 본 내용을 토대로, 이번에는 GLUE dataset의 mnli task를 수행하는 프로젝트를 커스텀 프로젝트 형태로 진행해 봅시다.\n",
        "\n",
        "- mnli task는 이전 스텝에서 사용한 BERT를 사용하면 학습이 제대로 되지 않습니다. [여기](https://huggingface.co/models)를 참조하여 BERT가 아닌 다른 모델을 선택하세요. tensorflow와 해당 모델에 대한 task로 검색하면 사용할 수 있는 모델이 나옵니다. 그 후 선택한 모델의 _tokenizer_와 해당 모델에 대한 task 와 모델 의 정보를 [여기](https://huggingface.co/docs/transformers/index)에서 찾아 여러분의 프로젝트를 완성해 보세요.\n",
        "\n",
        "- 그냥 run_glue.py를 돌려보는 방식으로 진행하는 것을 원하는 것은 아닙니다. 아래와 같은 순서를 지켜서 진행해 주세요"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "460f3c12",
      "metadata": {
        "id": "460f3c12"
      },
      "source": [
        "1. 라이브러리 버전을 확인해 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56067a96",
      "metadata": {
        "id": "56067a96",
        "outputId": "fa4846c9-31a9-4f5b-a8a7-4f19cba162b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n",
            "1.21.4\n",
            "4.11.3\n",
            "1.1\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification, AutoConfig\n",
        "from dataclasses import asdict\n",
        "from transformers.data.processors.utils import DataProcessor, InputExample, InputFeatures\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(transformers.__version__)\n",
        "print(argparse.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "343e5573",
      "metadata": {
        "id": "343e5573"
      },
      "outputs": [],
      "source": [
        "DEPRECATION_WARNING = (\n",
        "    \"This {0} will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets \"\n",
        "    \"library. You can have a look at this example script for pointers: \"\n",
        "    \"https://github.com/huggingface/transformers/blob/main/examples/pytorch/text-classification/run_glue.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20b2f6fd",
      "metadata": {
        "id": "20b2f6fd"
      },
      "source": [
        "# STEP 1. mnli 데이터셋을 분석해 보기\n",
        "\n",
        "- tensorflow-datasets를 이용하여 glue/mnli를 다운로드하려면 tensorflow-datasets 라이브러리 버전을 올려야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf1050c7",
      "metadata": {
        "collapsed": true,
        "id": "bf1050c7",
        "outputId": "ffb721a8-ff7f-47f6-cd3a-22de5365a298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.9/site-packages (4.4.0)\n",
            "Collecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.7.0-py3-none-any.whl (4.7 MB)\n",
            "     |████████████████████████████████| 4.7 MB 7.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (0.12.0)\n",
            "Collecting etils[epath]\n",
            "  Downloading etils-0.8.0-py3-none-any.whl (127 kB)\n",
            "     |████████████████████████████████| 127 kB 83.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (2.26.0)\n",
            "Requirement already satisfied: dill in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (0.3.4)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.16.0)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: promise in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (3.19.1)\n",
            "Requirement already satisfied: termcolor in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.1.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (1.21.4)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from tensorflow-datasets) (4.62.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: zipp in /opt/conda/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets) (3.6.0)\n",
            "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from etils[epath]->tensorflow-datasets) (4.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
            "Installing collected packages: etils, toml, tensorflow-datasets\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.4.0\n",
            "    Uninstalling tensorflow-datasets-4.4.0:\n",
            "      Successfully uninstalled tensorflow-datasets-4.4.0\n",
            "Successfully installed etils-0.8.0 tensorflow-datasets-4.7.0 toml-0.10.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-datasets -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da6f31f9",
      "metadata": {
        "collapsed": true,
        "colab": {
          "referenced_widgets": [
            "b4411f1927b943fcadbec1657765439e",
            "796d3a8c10c34b81a1aeb7e4ca1d56db",
            "b57f564604e5475b81f2e8dca8cc7841",
            ""
          ]
        },
        "id": "da6f31f9",
        "outputId": "16606f58-4c10-4002-d5cd-5f4a03c34ec3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: glue/mnli/2.0.0\n",
            "INFO:absl:Load dataset info from /tmp/tmp4thpf0xxtfds\n",
            "INFO:absl:Generating dataset glue (/aiffel/tensorflow_datasets/glue/mnli/2.0.0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset 298.29 MiB (download: 298.29 MiB, generated: 100.56 MiB, total: 398.85 MiB) to /aiffel/tensorflow_datasets/glue/mnli/2.0.0...\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4411f1927b943fcadbec1657765439e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "796d3a8c10c34b81a1aeb7e4ca1d56db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b57f564604e5475b81f2e8dca8cc7841",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading https://dl.fbaipublicfiles.com/glue/data/MNLI.zip into /aiffel/tensorflow_datasets/downloads/dl.fbaipublicfiles.com_glue_MNLIdNe8cK2kTBCG0bqBz2JxwShRT2KfuO3NVIwROTnjtfI.zip.tmp.878a1dbca1584f0e8a6934cfc4813665...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/5 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-train.tfrecord...:   0%|          | 0/392702 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-train.tfrecord. Number of examples: 392702 (shards: [392702])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_matched examples...:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-validation_matched.tfrecord...:   0%|          | 0/9815 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-validation_matched.tfrecord. Number of examples: 9815 (shards: [9815])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation_mismatched examples...:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-validation_mismatched.tfrecord...:   0%|          | 0/9832 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-validation_mismatched.tfrecord. Number of examples: 9832 (shards: [9832])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test_matched examples...:   0%|          | 0/9796 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-test_matched.tfrecord...:   0%|          | 0/9796 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-test_matched.tfrecord. Number of examples: 9796 (shards: [9796])\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test_mismatched examples...:   0%|          | 0/9847 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling glue-test_mismatched.tfrecord...:   0%|          | 0/9847 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Done writing glue-test_mismatched.tfrecord. Number of examples: 9847 (shards: [9847])\n",
            "INFO:absl:Constructing tf.data.Dataset glue for split None, from /aiffel/tensorflow_datasets/glue/mnli/2.0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset glue downloaded and prepared to /aiffel/tensorflow_datasets/glue/mnli/2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "392702"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data, info = tfds.load('glue/mnli', with_info=True)\n",
        "info.splits['train'].num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27196c4",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3a2b0bfa9cb5438d941911b86b9acc4a",
            "c2f9d98b9e2d498fa3029f9f8bc33198",
            "1044257d27e64f1e9108483e587ce794",
            "",
            "3deb8da90dca457bb8591ebbf48a4e69"
          ]
        },
        "id": "c27196c4",
        "outputId": "333e8caa-66c3-4c5f-f9c4-01ca613bec41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a2b0bfa9cb5438d941911b86b9acc4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2f9d98b9e2d498fa3029f9f8bc33198",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset glue/mnli (download: 298.29 MiB, generated: 78.65 MiB, post-processed: Unknown size, total: 376.95 MiB) to /aiffel/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1044257d27e64f1e9108483e587ce794",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/313M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset glue downloaded and prepared to /aiffel/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3deb8da90dca457bb8591ebbf48a4e69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 392702\n",
            "    })\n",
            "    validation_matched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9815\n",
            "    })\n",
            "    validation_mismatched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9832\n",
            "    })\n",
            "    test_matched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9796\n",
            "    })\n",
            "    test_mismatched: Dataset({\n",
            "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
            "        num_rows: 9847\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "huggingface_mnli_dataset = load_dataset('glue', 'mnli')\n",
        "print(huggingface_mnli_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8dec28",
      "metadata": {
        "id": "ba8dec28",
        "outputId": "2ddc1d90-1167-4a49-eac5-621dd6ddc593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 392702\n",
              "    })\n",
              "    validation_matched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9815\n",
              "    })\n",
              "    validation_mismatched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9832\n",
              "    })\n",
              "    test_matched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9796\n",
              "    })\n",
              "    test_mismatched: Dataset({\n",
              "        features: ['premise', 'hypothesis', 'label', 'idx'],\n",
              "        num_rows: 9847\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "huggingface_mnli_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3843ca05",
      "metadata": {
        "id": "3843ca05"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30cfd156",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a8b58d40f361449e9f246d1db6cbb0f3",
            "e76b29daa77449e89eb60f84d358c608",
            "c21462c640564ffaaa72f3a0d8e65d12",
            "2d81899fb64941c9a8c74145e996184e",
            "d63c7e4936a8406387f87fb435e986d1",
            "346b71e07231445ebd23934c18665ae8"
          ]
        },
        "id": "30cfd156",
        "outputId": "6315373e-f9b2-4138-a682-5e85005f4f1b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8b58d40f361449e9f246d1db6cbb0f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e76b29daa77449e89eb60f84d358c608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c21462c640564ffaaa72f3a0d8e65d12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d81899fb64941c9a8c74145e996184e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d63c7e4936a8406387f87fb435e986d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "346b71e07231445ebd23934c18665ae8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "huggingface_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
        "\n",
        "huggingface_model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e42f90f",
      "metadata": {
        "id": "8e42f90f",
        "outputId": "11789851-f5d5-42e0-df7c-bec047cdd0f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TakeDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['train'].take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea3ce509",
      "metadata": {
        "id": "ea3ce509",
        "outputId": "7c708d7f-19d8-48bb-aefb-01b1b9222ca6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{Split('train'): <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'validation_matched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'validation_mismatched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'test_matched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>,\n",
              " 'test_mismatched': <PrefetchDataset shapes: {hypothesis: (), idx: (), label: (), premise: ()}, types: {hypothesis: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string}>}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141da9dc",
      "metadata": {
        "id": "141da9dc",
        "outputId": "232893fe-d48f-4234-df30-7a1c9fbdd6ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', shape=(), dtype=string)\n",
            "tf.Tensor(b'Meaningful partnerships with stakeholders is crucial.', shape=(), dtype=string)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# 데이터셋 안에 어떤 항목이 정의되어 있는지 확인\n",
        "\n",
        "examples = data['train'].take(1)\n",
        "for example in examples:\n",
        "    premise = example['premise']\n",
        "    hypothesis = example['hypothesis']\n",
        "    label = example['label']\n",
        "    print(premise)\n",
        "    print(hypothesis)\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d48aa1",
      "metadata": {
        "id": "b3d48aa1"
      },
      "outputs": [],
      "source": [
        "class DataProcessor:\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"\n",
        "        Gets an example from a dict with tensorflow tensors.\n",
        "\n",
        "        Args:\n",
        "            tensor_dict: Keys and values should match the corresponding Glue\n",
        "                tensorflow_dataset examples.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of :class:`InputExample` for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of :class:`InputExample` for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of :class:`InputExample` for the test set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def tfds_map(self, example):\n",
        "        \"\"\"\n",
        "        Some tensorflow_datasets datasets are not formatted the same way the GLUE datasets are. This method converts\n",
        "        examples to the correct format.\n",
        "        \"\"\"\n",
        "        if len(self.get_labels()) > 1:\n",
        "            example.label = self.get_labels()[int(example.label)]\n",
        "        return example\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
        "            return list(csv.reader(f, delimiter=\"\\t\", quotechar=quotechar))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f199e8",
      "metadata": {
        "id": "91f199e8"
      },
      "source": [
        "# STEP 2. MNLIProcessor클래스 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740062d7",
      "metadata": {
        "id": "740062d7"
      },
      "outputs": [],
      "source": [
        "class MNLIProcessor(DataProcessor):\n",
        "    \"\"\"Processor for the MNLI data set (GLUE version).\"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return InputExample(\n",
        "            tensor_dict[\"idx\"].numpy(),\n",
        "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
        "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
        "            str(tensor_dict[\"label\"].numpy()),\n",
        "        )\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            text_a = line[8]\n",
        "            text_b = line[9]\n",
        "            label = None if set_type == \"test\" else line[-1]\n",
        "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "        return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6024e8",
      "metadata": {
        "id": "8e6024e8"
      },
      "outputs": [],
      "source": [
        "# 원본 데이터셋을 처리하여 모델에 입력할 수 있도록 정리해 주는 클래스\n",
        "\n",
        "class MrpcProcessor(DataProcessor):\n",
        "    \"\"\"Processor for the MRPC data set (GLUE version).\"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def get_example_from_tensor_dict(self, tensor_dict):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return InputExample(\n",
        "            tensor_dict[\"idx\"].numpy(),\n",
        "            tensor_dict[\"hypothesis\"].numpy().decode(\"utf-8\"),\n",
        "            tensor_dict[\"premise\"].numpy().decode(\"utf-8\"),\n",
        "            str(tensor_dict[\"label\"].numpy()),\n",
        "        )\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        print(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"dev.tsv\")), \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return [\"contradiction\", \"entailment\", \"neutral\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training, dev and test sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            guid = \"%s-%s\" % (set_type, line[0])\n",
        "            text_a = line[8]\n",
        "            text_b = line[9]\n",
        "            label = None if set_type == \"test\" else line[-1]\n",
        "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "        return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d57021",
      "metadata": {
        "scrolled": true,
        "id": "28d57021",
        "outputId": "bdb0efdb-99f2-40bb-e191-1e085234164d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------원본데이터------\n",
            "{'hypothesis': <tf.Tensor: shape=(), dtype=string, numpy=b'Meaningful partnerships with stakeholders is crucial.'>, 'idx': <tf.Tensor: shape=(), dtype=int32, numpy=16399>, 'label': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'premise': <tf.Tensor: shape=(), dtype=string, numpy=b'In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.'>}\n",
            "------processor 가공데이터------\n",
            "InputExample(guid=16399, text_a='In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', text_b='Meaningful partnerships with stakeholders is crucial.', label='1')\n"
          ]
        }
      ],
      "source": [
        "processor = MnliProcessor()\n",
        "examples = data['train'].take(1)\n",
        "\n",
        "for example in examples:\n",
        "    print('------원본데이터------')\n",
        "    print(example)  \n",
        "    example = processor.get_example_from_tensor_dict(example)\n",
        "    print('------processor 가공데이터------')\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa55b70",
      "metadata": {
        "id": "daa55b70",
        "outputId": "0a64b8e0-363b-4ecc-90e9-9beb9c43c771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InputExample(guid=16399, text_a='In recognition of these tensions, LSC has worked diligently since 1995 to convey the expectations of the State Planning Initiative and to establish meaningful partnerships with stakeholders aimed at fostering a new symbiosis between the federal provider and recipients of legal services funding.', text_b='Meaningful partnerships with stakeholders is crucial.', label='entailment')\n"
          ]
        }
      ],
      "source": [
        "examples = (data['train'].take(1))\n",
        "for example in examples:\n",
        "    example = processor.get_example_from_tensor_dict(example)\n",
        "    example = processor.tfds_map(example)\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740eddba",
      "metadata": {
        "id": "740eddba",
        "outputId": "ced68068-f886-4f1e-9606-13af7f3ae0a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['contradiction', 'entailment', 'neutral']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 실제 label을 확인하여 Binary Classification 문제로 잘 정의되고 있는지 확인\n",
        "label_list = processor.get_labels()\n",
        "label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4c98293",
      "metadata": {
        "id": "b4c98293",
        "outputId": "014fe71c-a09e-4f3d-b922-cf1cad2f6b18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'contradiction': 0, 'entailment': 1, 'neutral': 2}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "label_map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843dbd55",
      "metadata": {
        "id": "843dbd55"
      },
      "source": [
        "# STEP 3. 위에서 구현한 processor 및 Huggingface에서 제공하는 tokenizer를 활용하여 데이터셋 구성하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a4d5dce",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ee5ac8c878214c8e9c53549e1008b46f",
            "3cb46157c78a4b2b93131ac93ed2e4d5",
            "76ba73f817044bf5943b52ccde4a6385",
            "9392b440e45448b5a455404e6f0c0bb8",
            "e855ab4512344b1b96f3c6f14dfec3db"
          ]
        },
        "id": "4a4d5dce",
        "outputId": "957933a4-2e5d-4507-8bde-f3704338e135"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee5ac8c878214c8e9c53549e1008b46f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/258 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cb46157c78a4b2b93131ac93ed2e4d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ba73f817044bf5943b52ccde4a6385",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9392b440e45448b5a455404e6f0c0bb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
            "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e855ab4512344b1b96f3c6f14dfec3db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "huggingface_tokenizer = AutoTokenizer.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")\n",
        "\n",
        "huggingface_model = AutoModelForSequenceClassification.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c209be8",
      "metadata": {
        "collapsed": true,
        "id": "6c209be8",
        "outputId": "49a93e93-ed97-4784-dd22-267f7d974952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'premise': ['Conceptually cream skimming has two basic dimensions - product and geography.', 'you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the Braves decide to call to recall a guy from triple A then a double A guy goes up to replace him and a single A guy goes up to replace him', 'One of our number will carry out your instructions minutely.', 'How do you know? All this is their information again.', \"yeah i tell you what though if you go price some of those tennis shoes i can see why now you know they're getting up in the hundred dollar range\"], 'hypothesis': ['Product and geography are what make cream skimming work. ', 'You lose the things to the following level if the people recall.', 'A member of my team will execute your orders with immense precision.', 'This information belongs to them.', 'The tennis shoes have a range of prices.'], 'label': [1, 0, 0, 0, 1], 'idx': [0, 1, 2, 3, 4]}\n",
            "{'input_ids': [[101, 17158, 2135, 6949, 8301, 25057, 2038, 2048, 3937, 9646, 1011, 4031, 1998, 10505, 1012, 102, 4031, 1998, 10505, 2024, 2054, 2191, 6949, 8301, 25057, 2147, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2017, 2113, 2076, 1996, 2161, 1998, 1045, 3984, 2012, 2012, 2115, 2504, 7910, 2017, 4558, 2068, 2000, 1996, 2279, 2504, 2065, 2065, 2027, 5630, 2000, 9131, 1996, 1996, 6687, 2136, 1996, 13980, 5630, 2000, 2655, 2000, 9131, 1037, 3124, 2013, 6420, 1037, 2059, 1037, 3313, 1037, 3124, 3632, 2039, 2000, 5672, 2032, 1998, 1037, 2309, 1037, 3124, 3632, 2039, 2000, 5672, 2032, 102, 2017, 4558, 1996, 2477, 2000, 1996, 2206, 2504, 2065, 1996, 2111, 9131, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2028, 1997, 2256, 2193, 2097, 4287, 2041, 2115, 8128, 3371, 2135, 1012, 102, 1037, 2266, 1997, 2026, 2136, 2097, 15389, 2115, 4449, 2007, 14269, 11718, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2129, 2079, 2017, 2113, 1029, 2035, 2023, 2003, 2037, 2592, 2153, 1012, 102, 2023, 2592, 7460, 2000, 2068, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3398, 1045, 2425, 2017, 2054, 2295, 2065, 2017, 2175, 3976, 2070, 1997, 2216, 5093, 6007, 1045, 2064, 2156, 2339, 2085, 2017, 2113, 2027, 1005, 2128, 2893, 2039, 1999, 1996, 3634, 7922, 2846, 102, 1996, 5093, 6007, 2031, 1037, 2846, 1997, 7597, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ],
      "source": [
        "def transform(data):\n",
        "  return huggingface_tokenizer(\n",
        "      data['premise'],\n",
        "      data['hypothesis'],\n",
        "      truncation = True,\n",
        "      padding = 'max_length',\n",
        "      return_token_type_ids = False,\n",
        "      )\n",
        "  \n",
        "examples = huggingface_mnli_dataset['train'][:5]\n",
        "examples_transformed = transform(examples)\n",
        "\n",
        "print(examples)\n",
        "print(examples_transformed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "543144f0",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e5db5b3355a04619844c82d34728f0b6",
            "c6c611f302ab44bba1e9fe18722aaaa0",
            "f2fb61fbe6a14c848744c09bc169b6dc",
            "19ef566409774878b2c9b866b459fcd5",
            "49db9b578ca54e20b65c89791f81cf4e"
          ]
        },
        "id": "543144f0",
        "outputId": "ffe3f1c6-9825-46d5-d04b-e84ce29cbc34"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5db5b3355a04619844c82d34728f0b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/393 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6c611f302ab44bba1e9fe18722aaaa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2fb61fbe6a14c848744c09bc169b6dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19ef566409774878b2c9b866b459fcd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49db9b578ca54e20b65c89791f81cf4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "encoded_dataset = huggingface_mnli_dataset.map(transform, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f148e0",
      "metadata": {
        "id": "39f148e0"
      },
      "outputs": [],
      "source": [
        "def _glue_convert_examples_to_features(examples, tokenizer, max_length, processor, label_list=None, output_mode=\"claasification\") :\n",
        "    if max_length is None :\n",
        "        max_length = tokenizer.max_len\n",
        "    if label_list is None:\n",
        "        label_list = processor.get_labels()\n",
        "        print(\"Using label list %s\" % (label_list))\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "    labels = [label_map[example.label] for example in examples]\n",
        "\n",
        "    batch_encoding = tokenizer(\n",
        "        [(example.text_a, example.text_b) for example in examples],\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    features = []\n",
        "    for i in range(len(examples)):\n",
        "        inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
        "\n",
        "        feature = InputFeatures(**inputs, label=labels[i])\n",
        "        features.append(feature)\n",
        "\n",
        "    for i, example in enumerate(examples[:5]):\n",
        "        print(\"*** Example ***\")\n",
        "        print(\"guid: %s\" % (example.guid))\n",
        "        print(\"features: %s\" % features[i])\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d2c08b",
      "metadata": {
        "id": "08d2c08b"
      },
      "outputs": [],
      "source": [
        "def tf_glue_convert_examples_to_features(examples, \n",
        "                                         tokenizer, \n",
        "                                         max_length, \n",
        "                                         processor, \n",
        "                                         label_list=None, \n",
        "                                         output_mode=\"classification\") :\n",
        "    \"\"\"\n",
        "    :param examples: tf.data.Dataset\n",
        "    :param tokenizer: pretrained tokenizer\n",
        "    :param max_length: example의 최대 길이(기본값 : tokenizer의 max_len)\n",
        "    :param task: GLUE task 이름\n",
        "    :param label_list: 라벨 리스트\n",
        "    :param output_mode: \"regression\" or \"classification\"\n",
        "\n",
        "    :return: task에 맞도록 feature가 구성된 tf.data.Dataset\n",
        "    \"\"\"\n",
        "    examples = [processor.tfds_map(processor.get_example_from_tensor_dict(example)) for example in examples]\n",
        "    features = _glue_convert_examples_to_features(examples, tokenizer, max_length, processor)\n",
        "    label_type = tf.int64\n",
        "\n",
        "    def gen():\n",
        "        for ex in features:\n",
        "            d = {k: v for k, v in asdict(ex).items() if v is not None}\n",
        "            label = d.pop(\"label\")\n",
        "            yield (d, label)\n",
        "\n",
        "    input_names = [\"input_ids\"] + tokenizer.model_input_names\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({k: tf.int32 for k in input_names}, label_type),\n",
        "        ({k: tf.TensorShape([None]) for k in input_names}, tf.TensorShape([])),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d3fddc",
      "metadata": {
        "id": "83d3fddc"
      },
      "outputs": [],
      "source": [
        "# 최종적으로 모델에 전달될 tf.data.Dataset 인스턴스를 생성\n",
        "train_dataset = tf_glue_convert_examples_to_features(data['train'], \n",
        "                                                     tokenizer, max_length=128, processor=processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b3964f",
      "metadata": {
        "id": "39b3964f",
        "outputId": "e8d933a4-06e7-42f7-ac13-68a3a434a2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
            "array([  101,  1999,  5038,  1997,  2122, 13136,  1010,  1048, 11020,\n",
            "        2038,  2499, 29454, 29206, 14626,  2144,  2786,  2000, 16636,\n",
            "        1996, 10908,  1997,  1996,  2110,  4041,  6349,  1998,  2000,\n",
            "        5323, 15902, 13797,  2007, 22859,  6461,  2012,  6469,  2075,\n",
            "        1037,  2047, 25353, 14905, 10735,  2483,  2090,  1996,  2976,\n",
            "       10802,  1998, 15991,  1997,  3423,  2578,  4804,  1012,   102,\n",
            "       15902, 13797,  2007, 22859,  2003, 10232,  1012,   102,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
            "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(), dtype=int64, numpy=1>)\n"
          ]
        }
      ],
      "source": [
        "examples = train_dataset.take(1)\n",
        "for example in examples:\n",
        "    print(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "441c6a20",
      "metadata": {
        "id": "441c6a20"
      },
      "outputs": [],
      "source": [
        "# train 데이터셋\n",
        "train_dataset = tf_glue_convert_examples_to_features(data['train'], tokenizer, max_length=128, processor=processor)\n",
        "train_dataset_batch = train_dataset.shuffle(100).batch(16).repeat(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbc9562",
      "metadata": {
        "id": "bdbc9562"
      },
      "outputs": [],
      "source": [
        "# validation 데이터셋\n",
        "validation_dataset = tf_glue_convert_examples_to_features(data['validation_matched'], tokenizer, max_length=128, processor=processor)\n",
        "validation_dataset_batch = validation_dataset.shuffle(100).batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabbdeef",
      "metadata": {
        "id": "cabbdeef"
      },
      "outputs": [],
      "source": [
        "# test 데이터셋\n",
        "test_dataset = tf_glue_convert_examples_to_features(data['test_matched'], tokenizer, max_length=128, processor=processor)\n",
        "test_dataset_batch = test_dataset.shuffle(100).batch(16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a58fa6d",
      "metadata": {
        "id": "3a58fa6d"
      },
      "source": [
        "# STEP 4. model을 생성하여 학습 및 테스트를 진행해 보기\n",
        "\n",
        "- 혹시 STEP 2의 진행에 어려움을 겪고 계신다면 transformer 프로젝트 내부를 살펴보시면 참고할만한 예시 코드를 찾아볼 수 있을 것입니다. transformers의 공식 [github](https://github.com/huggingface/transformers)을 참고하는 것도 좋은 방법이에요!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a7a7f3f",
      "metadata": {
        "id": "5a7a7f3f"
      },
      "outputs": [],
      "source": [
        "num_classes = len(processor.get_labels())\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3be0d7",
      "metadata": {
        "scrolled": true,
        "id": "2f3be0d7",
        "outputId": "21694dc5-1f8e-4550-a4e0-230e94ae106e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  109482240 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 109,483,778\n",
            "Trainable params: 109,483,778\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0b1bf89",
      "metadata": {
        "collapsed": true,
        "id": "c0b1bf89",
        "outputId": "9f2ac483-fb63-45c9-f4ab-0cbe31c7d5c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:769 train_step\n        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:212 __call__\n        batch_dim = tf.shape(y_t)[0]\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1041 _slice_helper\n        return strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1214 strided_slice\n        op = gen_array_ops.strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10538 strided_slice\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_13/1303136026.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 이전 스텝에서 배치처리를 진행한 데이터셋(xxxx_dataset_batch)을 활용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(train_dataset, \n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m115\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/transformers/modeling_tf_utils.py:769 train_step\n        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py:212 __call__\n        batch_dim = tf.shape(y_t)[0]\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1041 _slice_helper\n        return strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1214 strided_slice\n        op = gen_array_ops.strided_slice(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10538 strided_slice\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: slice index 0 of dimension 0 out of bounds. for '{{node strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](Shape, strided_slice/stack, strided_slice/stack_1, strided_slice/stack_2)' with input shapes: [0], [1], [1], [1] and with computed input tensors: input[1] = <0>, input[2] = <1>, input[3] = <1>.\n"
          ]
        }
      ],
      "source": [
        "# 이미 잘 훈련된 BERT 모델을 가져다가 fine-tuning하는 작업\n",
        "\n",
        "# 이전 스텝에서 배치처리를 진행한 데이터셋(xxxx_dataset_batch)을 활용\n",
        "model.fit(train_dataset, \n",
        "          epochs=3, \n",
        "          steps_per_epoch=115, \n",
        "          validation_data=validation_dataset_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951845cd",
      "metadata": {
        "id": "951845cd"
      },
      "outputs": [],
      "source": [
        "# Trainer을 활용하는 형태로 모델 재생성\n",
        "from transformers import Trainer, TrainingArguments\n",
        "output_dir = os.getenv('HOME')+'/aiffel/transformers'\n",
        "metric_name = 'accuracy'\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir, # output이 저장될 경로\n",
        "    evaluation_strategy=\"epoch\", #evaluation하는 빈도\n",
        "    learning_rate = 2e-5, #learning_rate\n",
        "    per_device_train_batch_size = 8, # 각 device 당 batch size\n",
        "    per_device_eval_batch_size = 8, # evaluation 시에 batch size\n",
        "    num_train_epochs = 1, # train 시킬 총 epochs\n",
        "    weight_decay = 0.01, # weight decay\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bf190c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "43e0551949024f378e3b4492a5843291"
          ]
        },
        "id": "93bf190c",
        "outputId": "f92539ea-65ce-4a90-992a-3100e97816ea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "43e0551949024f378e3b4492a5843291",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric('glue', 'mnli')\n",
        "\n",
        "def compute_metrics(eval_pred):    \n",
        "    predictions,labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references = labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a35ff76",
      "metadata": {
        "id": "0a35ff76",
        "outputId": "05f42a46-4ee2-487e-8a00-b6ef27707a21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\n",
            "***** Running training *****\n",
            "  Num examples = 392702\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 49088\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49088' max='49088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [49088/49088 5:55:40, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.292800</td>\n",
              "      <td>0.930875</td>\n",
              "      <td>0.813653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17500/pytorch_model.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-21000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-21000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-21000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-21500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-21500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-21500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-24000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-24000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-24500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-24500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-33000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-33000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-33000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-33500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-33500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-33500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35000/config.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-38000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-38000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-38000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-38500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-38500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-38500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-39000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-39000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-39000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-39500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-39500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-39500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-40000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-40000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-40000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-40500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-40500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-40500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-41000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-41000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-41000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-41500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-41500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-41500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-42000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-42000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-42000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-42500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-42500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-42500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-43000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-43000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-43000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-43500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-43500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-43500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-44000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-44000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-44000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-44500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-44500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-44500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-45000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-45000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-45000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-45500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-45500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-45500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-46000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-46000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-46000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-46500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-46500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-46500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-47000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-47000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-47000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-47500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-47500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-47500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-48000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-48000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-48000/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-48500\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-48500/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-48500/pytorch_model.bin\n",
            "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-49000\n",
            "Configuration saved in /aiffel/aiffel/transformers/checkpoint-49000/config.json\n",
            "Model weights saved in /aiffel/aiffel/transformers/checkpoint-49000/pytorch_model.bin\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9815\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=49088, training_loss=0.29948605905922016, metrics={'train_runtime': 21341.9578, 'train_samples_per_second': 18.4, 'train_steps_per_second': 2.3, 'total_flos': 5.202114009364685e+16, 'train_loss': 0.29948605905922016, 'epoch': 1.0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=huggingface_model,                           # 학습시킬 model\n",
        "    args=training_arguments,                  # TrainingArguments을 통해 설정한 arguments\n",
        "    train_dataset=encoded_dataset['train'],    # training dataset\n",
        "    eval_dataset=encoded_dataset['validation_matched'],       # evaluation dataset\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03676efd",
      "metadata": {
        "id": "03676efd",
        "outputId": "28f2075a-2ab5-49fd-a04f-9b964642b01a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, hypothesis, premise.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9796\n",
            "  Batch size = 8\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "/pytorch/aten/src/THCUNN/ClassNLLCriterion.cu:108: cunn_ClassNLLCriterion_updateOutput_kernel: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_534/2286787279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_matched'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2114\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m             \u001b[0;31m# Update containers on host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2487\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ],
      "source": [
        "trainer.evaluate(encoded_dataset['test_matched'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고"
      ],
      "metadata": {
        "id": "lX7qGW4XKysW"
      },
      "id": "lX7qGW4XKysW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 이번 프로젝트에서 어려웠던 점\n",
        " \n",
        "(1) CUDA 메모리 오류가 계속 떠 학습 과정이 쉽지않았습니다."
      ],
      "metadata": {
        "id": "ojmxzLRyK1cS"
      },
      "id": "ojmxzLRyK1cS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 프로젝트를 진행하면서 알게된 부분 또는 아직 이해하지 못한 부분\n",
        "\n",
        "(1) CUDA 메모리 오류를 해결하기 위한 방법\n",
        "- batch_size 조절\n",
        "- 더 작은 모델 불러오기\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cMgNvnfQLhyy"
      },
      "id": "cMgNvnfQLhyy"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}